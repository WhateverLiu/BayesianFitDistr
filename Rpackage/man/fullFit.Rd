% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fullFit.R
\name{fullFit}
\alias{fullFit}
\title{End-to-end Inflated Transformed Beta Fitting Pipeline}
\usage{
fullFit(
  mdr,
  cdr,
  windowSize,
  slidingSpeed,
  sampleSize,
  NsampleSets = 100L,
  interpolationMethod = "linear",
  linearIntpoThenCpp = TRUE,
  targetMDRs = c(1:10000, seq(10000L + 10L, 100000L - 10L, by = 10L))/1e+05,
  randomSeed = 123L,
  maxCore = parallel::detectCores(),
  deductible = NULL,
  isDedFranchise = TRUE,
  givenP0 = NULL,
  nonDegenerateOldDistrs = NULL,
  sampleWeightOnOldDistrs = 0.8,
  empDistrSupportSize = 64L,
  regridMethod = "lr",
  tempDir = "../tempFiles/CharlieTempMP/C",
  figureDir = "../figure",
  fitToBiasCorrectedPMFs = FALSE,
  abc = matrix(c(4, 5, 6)),
  abcLB = c(1.01, 0.1, 0.1),
  abcUB = c(30, 30, 30),
  startingPmf = 0L,
  scaleEps = 1e-08,
  scaleMaxit = 100L,
  distanceFun = "likelihood",
  max_iterations = 100L,
  RIBlib = "Numerical Recipes",
  sequentialUpdate = -1,
  hgrad = 0,
  centralDiff = TRUE,
  verbose = TRUE,
  m = 6,
  epsilon = 1e-05,
  epsilon_rel = 1e-05,
  past = 1,
  delta = 1e-10,
  max_submin = 10,
  max_linesearch = 20,
  min_step = 1e-20,
  max_step = 1e+20,
  ftol = 1e-04,
  wolfe = 0.9
)
}
\arguments{
\item{mdr}{MDRs in claims data. \code{mdr} and \code{cdr} will be reshuffled and 
reordered internally.}

\item{cdr}{Claim damage ratios in claims data.}

\item{windowSize}{A positive integer as the sliding window size.}

\item{slidingSpeed}{A positive integer as the sliding speed.}

\item{sampleSize}{Sample size for each member in the ensemble.}

\item{NsampleSets}{Ensemble size. Default to 100.}

\item{interpolationMethod}{Interpolation method, either \code{"linear"} or 
\code{"hyman"}. Default to \code{"linear"}, which invokes 
\code{\link[stats]{approxfun}(method = "linear")}.
\code{"hyman"} invokes \code{\link[stats]{splinefun}(method = "hyman")}. 
The argument controls how we interpolate the longest monotonic subsequence
of \eqn{P_0} (or \eqn{\max}). The interpolation function is then used to
estimate the \eqn{P_0} (or \eqn{\max}) at any MDR.}

\item{linearIntpoThenCpp}{A boolean. If \code{interpolationMethod} is 
\code{"linear"} and \code{linearIntpoThenCpp} is true, use the speed 
optimized version of routine for modeling \eqn{P_0}.}

\item{targetMDRs}{Prescribed MDRs. Default to the 18999 MDRs in coverage
A, B, C PMF tables: 0.00001, 0.00002, ..., 0.09999, 0.1000, 0.1001, 
0.1002 ..., 0.9999.}

\item{randomSeed}{Random seed. Default to \code{42}.}

\item{maxCore}{Maximum number of CPU cores to use. 
Default to \code{parallel::detectCores()}.}

\item{deductible}{Either \code{NULL} or a numeric vector of size 
\code{length(mdr)}. If not \code{NULL}, all elements should be 
\eqn{\in[0,1]}. Elements are ratios of deductibles to replacement values. 
Default to \code{NULL}.}

\item{isDedFranchise}{A boolean. \code{TRUE} implies the deductibles are
franchise deductibles. Default to \code{TRUE}. Ignored if 
\code{deductible==NULL}.}

\item{givenP0}{Either \code{NULL} or a numeric vector of size 
\code{length(mdr)}. If not \code{NULL}, \code{givenP0} will be the model 
for \eqn{P_0}.}

\item{nonDegenerateOldDistrs}{A list of old PMFs for Bayesian update. The list
should have the same length as \code{targetMDRs}. Each PMF is a list or 
data frame of size 2: the 1st vector is the support, and the 2nd vector 
is the probabilities. Default to \code{NULL}, which implies no Bayesian update.}

\item{sampleWeightOnOldDistrs}{Sampling weight in \code{[0, 1]} on the old 
distributions. Ignored if \code{nonDegenerateOldDistrs} is \code{NULL}.}

\item{empDistrSupportSize}{Support size in each of the result PMFs.}

\item{regridMethod}{Regrid method. \code{"lr"} implies linear regrid.
\code{"lmm"} implies local moment matching. \code{"r4"} implies four-point 
regrid. Default to \code{"lr"}.}

\item{tempDir}{A directory for saving computing progress. Default to
\code{"../tempFiles/CharlieTempMP/C"}. Will be created if nonexistent.}

\item{figureDir}{Path to the directory for saving plots. 
\code{figureDir = ""} silences visualization. The directory will be created
if nonexistent. Default to \code{"../figure"}.}

\item{fitToBiasCorrectedPMFs}{A boolean. \code{TRUE} will fit TrBs to
bias corrected empirical PMFs. Default to \code{FALSE}.}

\item{abc}{Initializations of \code{a,b,c} as a \eqn{3\times K} numeric 
matrix. Here \eqn{K} is the number of initializations. The function will 
fit each distribution using the \eqn{K} initializations, and then return  
the optimized parameters that lead to the best 
objective function value.}

\item{abcLB}{A numeric vector as the lower bounds on \code{a,b,c}.
An emptry vector \code{numeric(0)} implies no lower bounds. 
Supplying the lower bounds is strongly recommended. 
Default to \code{c(1.01,0.1,0.1)}. Note that \code{a<=1} implies 
a TrB distribution with infinite mean.}

\item{abcUB}{A numeric vector as the upper bounds on \code{a,b,c}. 
An emptry vector \code{numeric(0)} imples no upper bounds. 
Supplying the upper bounds is strongly recommended. 
Default to \code{c(30,30,30)}.}

\item{startingPmf}{An integer default to \code{0}:
\itemize{
\item{\code{-1}:}{ Invokes the plain fitting procedure, that is, for each PMF, 
the function will use each of the \eqn{K} initializations in \code{abc} to 
train a TrB, and among the \eqn{K} optimized parameters, select the one 
that leads to the best objective function value.}


\item{\code{0}:}{ Invokes the bidirectional sequential 
fitting procedure. It chooses the PMF associated to the median MDR in data
as the starting PMF. For each of the \eqn{K} initializations in \code{abc}, 
the function will fit the starting PMF, and then use the trained TrB 
parameters as the initialization for fitting the next/prior PMF. This
will end up with \eqn{K} optimized parameters for each PMF. The function 
will then return the one that leads to the best objective function value.
}

\item{\code{>=1}:}{  Similar to \code{0} but the index of 
the starting PMF is fixed to \code{startingPmf}. }
}}

\item{scaleEps}{Stop Newton's solver for parameter \code{d} if 
the difference between TrB's current limited mean and
its target limited mean becomes less than \code{scaleEps}.
Default to \code{1e-8}.}

\item{scaleMaxit}{Stop Newton's solver for parameter \code{d} if 
the number of iterations has reached \code{scaleMaxit}. 
Default to \code{100}.}

\item{distanceFun}{A string. Name of the distance function for optimization.
\itemize{

\item{\code{"likelihood"}:}{ Negative log-likelihood.}

\item{\code{"likelihoodDiscrete"}:}{ Discretize the TrB and then compute 
the negative log-likelihood, aka cross-entropy. Much slower due to 
frequent calls to TrB's CDF. No improvement over 
\code{"likelihood"} was found.}
  
\item{\code{"Komogorov"}:}{\href{https://en.wikipedia.org/wiki/Smooth_maximum}{ Smooth maximum} 
distance between CDFs. Slow. The smooth maximum ensures differentiability. }

\item{\code{"EuclideanCDF"}:}{ Euclidean distance between CDFs. Slow.}

\item{\code{"unbiasedLikelihoodDiscrete"}:}{ A research effort misled by the 
  "unbiased" discretization method described in R package \code{actuar}. 
  Such discretization preserves the PDF's mean, but the probabilities 
  will not sum up to 1. Use with caution.}
  
\item{\code{"unbiasedKomogorov"}:}{ A research effort misled by the 
  "unbiased" discretization method described in R package \code{actuar}. 
  Such discretization preserves the PDF's mean, but the probabilities 
  will not sum up to 1. Use with caution.}
  
\item{\code{"unbiasedEuclideanCDF"}:}{ A research effort misled by the 
  "unbiased" discretization method described in R package \code{actuar}. 
  Such discretization preserves the PDF's mean, but the probabilities 
  will not sum up to 1. Use with caution.}
}}

\item{max_iterations}{An L-BFGS-B algorithm parameter. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{RIBlib}{A string to specify which library should be used to 
compute the \href{https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function}{Regularized Incomplete Beta function}
that TrB CDF depends on. 
\itemize{
\item{\code{"Numerical Recipes"}}{ implements the textbook algorithm in
\href{https://e-maxx.ru/bookz/files/numerical_recipes.pdf}{Chapter 6.4, Numerical Recipes}.
\href{https://live.boost.org/doc/libs/1_54_0/libs/math/doc/html/math_toolkit/sf_beta/ibeta_function.html}{Boost}, 
which claims the textbook algorithm's series expansion converges less 
rapidly than its own approach, actually runs considerably slower because 
it pursues much higher numeric precision.
Such extreme precision turns out largely unncessary in our setting. 
\code{"Numerical Recipes"} is the default and 
the recommended choice.}

\item{\code{"R::pbeta"}}{ calls R's Beta CDF. It is slower than \code{"Numerical Recipes"}
but faster than \code{"Boost"}. In numerically pathological regions, 
\code{"R::pbeta"} is more precise than \code{"Numerical Recipes"} 
but less so than \code{"Boost"}.}

\item{\code{"Boost"}}{ calls \href{https://live.boost.org/doc/libs/1_54_0/libs/math/doc/html/math_toolkit/sf_beta/ibeta_function.html}{boost::math::ibeta}.
It is the slowest but yields much higher precision especially 
in numerically pathological regions.}
}}

\item{sequentialUpdate}{One-based index of the first PMF to be fitted 
during bi-directional sequential fitting. \code{-1} avoids using 
the bi-directional sequential fitting.}

\item{hgrad}{A nonnegative number as the \eqn{\Delta} for finite differencing. 
Default to \code{0} which implies to
use the internal default values: \code{6.055e-6} for central difference, 
\code{1.49e-8} for forward difference. The numbers are 
cubic and square roots of machine precision respectively.}

\item{centralDiff}{\code{TRUE} to use central difference for finite 
differencing. 
\code{FALSE} to use forward difference. Default to \code{TRUE} 
which is also strongly recommended.}

\item{verbose}{\code{TRUE} prints computing progress. Default \code{TRUE}.}

\item{m}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{epsilon}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{epsilon_rel}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{past}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{delta}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{max_submin}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{max_linesearch}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{min_step}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{max_step}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{ftol}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}

\item{wolfe}{Parameter in L-BFGS-B. Do not change the
default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.}
}
\value{
A list of objects procedurally generated during major computational 
stages. All the objects except for \code{TrBtable} are intermediaries 
saved for diagnostics.
\itemize{
  \item{\code{maxCore}:}{  The number of cores that were actually used. }
  \item{\code{mdrRangeInData}:}{  The range of MDRs in data. }
  \item{\code{p0models}:}{  Output from \code{\link{ensembleP0}}. }
  \item{\code{P0}:}{  The \eqn{P_0} model. A numeric vector of size 
    \code{length(targetMDRs)}. }
  \item{\code{windows}:}{  Output from \code{\link{computeWindows}}. }
  \item{\code{empDistrsLists}:}{  Output from \code{\link{estimateEmpPMFs}}. }
  \item{\code{condEmpDistrs}:}{  Output from \code{\link{extractMain}}. }
  \item{\code{startingPmf}:}{  Index of the first PMF that was fitted. }
  \item{\code{startingMDR}:}{  MDR associated to the starting PMF. 
    This only exists if \code{startingPmf >= 0}.  }
  \item{\code{optRst}:}{  Output from \code{\link{LBFGSBtrbFitList}}. }
  \item{\code{postDeductibleP0}:}{  
    The \eqn{P_0} model after subtracting the missing probability mass due 
    to deductibles. This only exists if \code{deductible} is not \code{NULL}. }
  \item{\code{TrBtable}:}{  Inflated Transformed Beta parameter table as a 
    6-column dataframe. The column names are \code{MDR,P0,a,b,c,d}. 
    Note that \code{max} is still missing and will be determined before
    discretization.}
}
}
\description{
An amalgamation of the building blocks in the fitting methodology,
including \code{\link{computeWindows}}, \code{\link{ensembleP0}}, 
\code{\link{estimateEmpPMFs}}, 
\code{\link{extractMain}}, \code{\link{LBFGSBtrbFitList}}, etc. 
The pipeline imports claims data, exports the inflated TrB parameter table,
manages deductibles, and incorporates Bayesian updates.
Outputs from major computational stages are saved in the return value
for diagnostics. Diagnostic visualizations can be made during the computation.
Users can type \code{fullFit} in the R console and read the documented code.
}
