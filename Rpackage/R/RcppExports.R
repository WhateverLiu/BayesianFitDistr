# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

p0ensembleLDSlinear <- function(rawMdr, dr, windowSize, slidingSpeed, eps, targetMDRs, Nsample, sampleSize, seed, maxCore) {
    .Call('_NGFMfitDistr_p0ensembleLDSlinear', PACKAGE = 'NGFMfitDistr', rawMdr, dr, windowSize, slidingSpeed, eps, targetMDRs, Nsample, sampleSize, seed, maxCore)
}

makeP0test <- function(mdr, dr, windowSize, slidingSpeed, eps) {
    .Call('_NGFMfitDistr_makeP0test', PACKAGE = 'NGFMfitDistr', mdr, dr, windowSize, slidingSpeed, eps)
}

p0ensembleLDSlinearOld <- function(rawMdr, dr, windowSize, slidingSpeed, eps, targetMDRs, Nsample, sampleSizeRatio, seed, maxCore) {
    .Call('_NGFMfitDistr_p0ensembleLDSlinearOld', PACKAGE = 'NGFMfitDistr', rawMdr, dr, windowSize, slidingSpeed, eps, targetMDRs, Nsample, sampleSizeRatio, seed, maxCore)
}

assignP0 <- function(p, p0) {
    invisible(.Call('_NGFMfitDistr_assignP0', PACKAGE = 'NGFMfitDistr', p, p0))
}

autoCorr <- function(x, maxCore = 1000L) {
    .Call('_NGFMfitDistr_autoCorr', PACKAGE = 'NGFMfitDistr', x, maxCore)
}

correctMeanBias <- function(distlist, mdrs, lim = 1.0, eps = 1e-10, maxCore = 1000L) {
    .Call('_NGFMfitDistr_correctMeanBias', PACKAGE = 'NGFMfitDistr', distlist, mdrs, lim, eps, maxCore)
}

distances <- function(distlist, param, scaleEps = 1e-8, scaleMaxit = 100L, maxCore = 1000L, distanceFun = "likelihood", RIBlib = "Numerical Recipes") {
    .Call('_NGFMfitDistr_distances', PACKAGE = 'NGFMfitDistr', distlist, param, scaleEps, scaleMaxit, maxCore, distanceFun, RIBlib)
}

#' Extract main part.
#' 
#' Remove \eqn{P_0}s from the PMFs in a list.
#' 
#' @param distlist  A list of PMFs. Each PMF is a list of two numeric vectors.
#' The first is the support. The second is the probabilities.
#' 
#' @param MDR  A numeric vector of the prescribed MDRs. Should have the same
#' size as \code{distlist}.
#' 
#' @param normalizeMainPart  A boolean value. Should we normalize the 
#' probabilities after removing \eqn{P_0}? Default to \code{TRUE}.
#' 
#' @param removeZeroPs  A boolean value. Some probabilities can be zeros in
#' \code{distlist}. Should we remove them along with their points on the
#' support? Default to \code{FALSE}.
#' 
#' @return A list of two:
#' 
#' \code{$conditionalDistrs}:  A list of PMFs to be fitted by TrBs.
#' 
#' \code{$lm1}: A numeric vector of the target limited means 
#' for constraining \eqn{\mathbb{E}[\min(X, 1)]} of the TrB models.
#' 
#' @inherit computeWindows details
#' 
#' @example  inst/examples/extractMain.R
#' 
extractMain <- function(distlist, MDR, normalizeMainPart = TRUE, removeZeroPs = FALSE) {
    .Call('_NGFMfitDistr_extractMain', PACKAGE = 'NGFMfitDistr', distlist, MDR, normalizeMainPart, removeZeroPs)
}

#'
#' Inflated Transformed Beta Discretization
#' 
#' \strong{F}ine-tuned \strong{D}iscretization for \strong{F}ulfilling \strong{QA}
#' requirements, i.e. FTDFQA. The function produces a PMF table from an 
#' inflated TrB parameter table.
#' 
#' @param TrBtable  A numeric matrix of 7 rows. Each column is a vector of
#' \code{(MDR, max, }\eqn{P_0}\code{, a, b, c, d)}.
#' 
#' @param supportSizes  An integer vector, e.g. \code{c(64, 42)}.
#' 
#' @param regridMethod  Regrid method: \code{"lr"} (linear regrid) or 
#' \code{"lmm"} (local moment matching) or \code{"r4"} (four-point regrid).
#' Default to \code{"lr"}.
#' 
#' @param outputProbsInRows  A boolean. \code{TRUE} will produce a PMF 
#' table (matrix) where every row is a vector of (\code{MDR, max}, \eqn{P_0}, 
#' \code{P1, ..., Pmax}). \code{FALSE} will store it in a column. 
#' Default to \code{FALSE}.
#' 
#' @param fineDiscretizationSize  An integer. Support size for raw 
#' discretization before tunning. Default to 2000.
#' 
#' @param verbose  A boolean. \code{TRUE} prints QA checking messages.
#' 
#' @param downScaleSupport  A boolean. When the raw discretization's mean is
#' less than MDR, \code{TRUE} will downscale the support to match the MDR, 
#' while \code{FALSE} will increase \eqn{P_0} and downscale the main part 
#' probabilities to match the MDR. Default to \code{FALSE}, which is the 
#' better choice from experiments.
#' 
#' @inheritParams LBFGSBtrbFitList
#' 
#' @inherit  computeWindows details
#' 
#' @return A list of two named objects:
#' \itemize{
#' \item\code{distTable}: A list of final PMF tables corresponding to 
#' \code{supportSizes}. 
#' 
#' Names of the tables in \code{distTable} are \code{p} succeeded by 
#' the support sizes. For example, 
#' if \code{supportSizes = c(42L, 64L)}, then the names would be
#' \code{'p42'} and \code{'p64'}.
#' 
#' If \code{outputProbsInRows = FALSE}, every column 
#' of \code{distTable$p42} or \code{distTable$p64} would be 
#' \code{MDR, max, P0, P1, ..., Pmax}. Otherwise the tables are transposed.
#' 
#' \item\code{distTableBeforeTune}: A list of PMF tables before tuning for
#' monotonicity requirements. These are returned for diagnostics.
#' }
#' 
#' @example inst/examples/FTDFQA.R
#' 
#' 
#' 
#' 
FTDFQA <- function(TrBtable, supportSizes, regridMethod = "lr", RIBlib = "Numerical Recipes", outputProbsInRows = FALSE, fineDiscretizationSize = 2000L, maxCore = 1000L, verbose = TRUE, downScaleSupport = FALSE) {
    .Call('_NGFMfitDistr_FTDFQA', PACKAGE = 'NGFMfitDistr', TrBtable, supportSizes, regridMethod, RIBlib, outputProbsInRows, fineDiscretizationSize, maxCore, verbose, downScaleSupport)
}

LBFGSBtrbFit <- function(abc_lm1, empDistr, abcLB = numeric(0), abcUB = numeric(0), scaleEps = 1e-8, scaleMaxit = 100L, distanceFun = "likelihood", max_iterations = 100L, RIBlib = "R::pbeta", hgrad = 0, centralDiff = TRUE, m = 6L, epsilon = 1e-5, epsilon_rel = 1e-5, past = 1L, delta = 1e-10, max_submin = 10L, max_linesearch = 20L, min_step = 1e-20, max_step = 1e+20, ftol = 1e-4, wolfe = 0.9) {
    .Call('_NGFMfitDistr_LBFGSBtrbFit', PACKAGE = 'NGFMfitDistr', abc_lm1, empDistr, abcLB, abcUB, scaleEps, scaleMaxit, distanceFun, max_iterations, RIBlib, hgrad, centralDiff, m, epsilon, epsilon_rel, past, delta, max_submin, max_linesearch, min_step, max_step, ftol, wolfe)
}

#' Fit TrBs
#'
#' Fit TrBs to a list of PMFs using \href{https://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B}{L-BFGS-B}. 
#' 
#' @param abc  Initializations of \code{a,b,c} as a \eqn{3\times K} numeric 
#' matrix. Here \eqn{K} is the number of initializations. The function will 
#' fit each distribution using the \eqn{K} initializations, and then return  
#' the optimized parameters that lead to the best 
#' objective function value.
#' 
#' @param lm1  A numeric vector of target limited means for constraining 
#' the TrBs.
#' 
#' @param empDistrList  A list of empirical PMFs. Each PMF is a list of two 
#' numeric vectors, the support and the probabilities.
#' 
#' @param abcLB  A numeric vector as the lower bounds on \code{a,b,c}.
#' An emptry vector \code{numeric(0)} implies no lower bounds. 
#' Supplying the lower bounds is strongly recommended. 
#' Default to \code{c(1.01,0.1,0.1)}. Note that \code{a<=1} implies 
#' a TrB distribution with infinite mean.
#' 
#' @param abcUB  A numeric vector as the upper bounds on \code{a,b,c}. 
#' An emptry vector \code{numeric(0)} imples no upper bounds. 
#' Supplying the upper bounds is strongly recommended. 
#' Default to \code{c(30,30,30)}.
#' 
#' @param scaleEps  Stop Newton's solver for parameter \code{d} if 
#' the difference between TrB's current limited mean and
#' its target limited mean becomes less than \code{scaleEps}.
#' Default to \code{1e-8}.
#' 
#' @param scaleMaxit  Stop Newton's solver for parameter \code{d} if 
#' the number of iterations has reached \code{scaleMaxit}. 
#' Default to \code{100}.
#' 
#' @param distanceFun  A string. Name of the distance function for optimization.
#' \itemize{
#' 
#' \item{\code{"likelihood"}:}{ Negative log-likelihood.}
#' 
#' \item{\code{"likelihoodDiscrete"}:}{ Discretize the TrB and then compute 
#' the negative log-likelihood, aka cross-entropy. Much slower due to 
#' frequent calls to TrB's CDF. No improvement over 
#' \code{"likelihood"} was found.}
#'   
#' \item{\code{"Komogorov"}:}{\href{https://en.wikipedia.org/wiki/Smooth_maximum}{ Smooth maximum} 
#' distance between CDFs. Slow. The smooth maximum ensures differentiability. }
#' 
#' \item{\code{"EuclideanCDF"}:}{ Euclidean distance between CDFs. Slow.}
#' 
#' \item{\code{"unbiasedLikelihoodDiscrete"}:}{ A research effort misled by the 
#'   "unbiased" discretization method described in R package \code{actuar}. 
#'   Such discretization preserves the PDF's mean, but the probabilities 
#'   will not sum up to 1. Use with caution.}
#'   
#' \item{\code{"unbiasedKomogorov"}:}{ A research effort misled by the 
#'   "unbiased" discretization method described in R package \code{actuar}. 
#'   Such discretization preserves the PDF's mean, but the probabilities 
#'   will not sum up to 1. Use with caution.}
#'   
#' \item{\code{"unbiasedEuclideanCDF"}:}{ A research effort misled by the 
#'   "unbiased" discretization method described in R package \code{actuar}. 
#'   Such discretization preserves the PDF's mean, but the probabilities 
#'   will not sum up to 1. Use with caution.}
#' }
#' 
#' 
#' @param max_iterations  An L-BFGS-B algorithm parameter. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param maxCore  The number of CPU cores for use. Default to 1000. A number
#'   greater than the actual number of logical processors will be capped.
#'   The bidirectional sequential fitting, which is the most likely to be used, 
#'   is single-threaded if the initialization \code{abc} is singular --- when
#'   \eqn{K=1}.
#'   
#' @param RIBlib  A string to specify which library should be used to 
#' compute the \href{https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function}{Regularized Incomplete Beta function}
#' that TrB CDF depends on. 
#' \itemize{
#' \item{\code{"Numerical Recipes"}}{ implements the textbook algorithm in
#' \href{https://e-maxx.ru/bookz/files/numerical_recipes.pdf}{Chapter 6.4, Numerical Recipes}.
#' \href{https://live.boost.org/doc/libs/1_54_0/libs/math/doc/html/math_toolkit/sf_beta/ibeta_function.html}{Boost}, 
#' which claims the textbook algorithm's series expansion converges less 
#' rapidly than its own approach, actually runs considerably slower because 
#' it pursues much higher numeric precision.
#' Such extreme precision turns out largely unncessary in our setting. 
#' \code{"Numerical Recipes"} is the default and 
#' the recommended choice.}
#' 
#' \item{\code{"R::pbeta"}}{ calls R's Beta CDF. It is slower than \code{"Numerical Recipes"}
#' but faster than \code{"Boost"}. In numerically pathological regions, 
#' \code{"R::pbeta"} is more precise than \code{"Numerical Recipes"} 
#' but less so than \code{"Boost"}.}
#' 
#' \item{\code{"Boost"}}{ calls \href{https://live.boost.org/doc/libs/1_54_0/libs/math/doc/html/math_toolkit/sf_beta/ibeta_function.html}{boost::math::ibeta}.
#' It is the slowest but yields much higher precision especially 
#' in numerically pathological regions.}
#' }
#' 
#' @param sequentialUpdate  One-based index of the first PMF to be fitted 
#' during bi-directional sequential fitting. \code{-1} avoids using 
#' the bi-directional sequential fitting.
#' 
#' @param hgrad  A nonnegative number as the \eqn{\Delta} for finite differencing. 
#' Default to \code{0} which implies to
#' use the internal default values: \code{6.055e-6} for central difference, 
#' \code{1.49e-8} for forward difference. The numbers are 
#' cubic and square roots of machine precision respectively.
#' 
#' @param centralDiff  \code{TRUE} to use central difference for finite 
#' differencing. 
#' \code{FALSE} to use forward difference. Default to \code{TRUE} 
#' which is also strongly recommended.
#' 
#' @param m  Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param epsilon  Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param epsilon_rel  Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param past  Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param delta Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param max_submin Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param max_linesearch Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param min_step Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param max_step  Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param ftol Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @param wolfe Parameter in L-BFGS-B. Do not change the
#' default value before consulting \href{https://github.com/yixuan/LBFGSpp}{LBFGSpp}.
#' 
#' @return A list of 3 objects:
#' \itemize{
#' \item{\code{param}:}{ A numeric matrix of 4 rows. \code{param[, i]} 
#' contains the optimized \code{a,b,c} and the input \code{lm1} for 
#' the \code{i}-th empirical PMF.}
#' 
#' \item{\code{fval}:}{ The final objective function values. A value of 
#' \code{1e300} implies the optimization has not converged and the 
#' corresponding parameters should be reanalyzed or discarded.}
#' 
#' \item{\code{niter}:}{ The number of iterations until convergence.}
#' }
#' 
#' 
#' @inherit  computeWindows details
#' 
#' @example  inst/examples/LBFGSBtrbFitList.R
#' 
#' 
LBFGSBtrbFitList <- function(abc, lm1, empDistrList, abcLB = as.numeric( c(1.01, 0.1, 0.1)), abcUB = as.numeric( c(30, 30, 30)), scaleEps = 1e-8, scaleMaxit = 100L, distanceFun = "likelihood", max_iterations = 100L, maxCore = 15L, RIBlib = "Numerical Recipes", sequentialUpdate = -1L, hgrad = 0, centralDiff = TRUE, m = 6L, epsilon = 1e-5, epsilon_rel = 1e-5, past = 1L, delta = 1e-10, max_submin = 10L, max_linesearch = 20L, min_step = 1e-20, max_step = 1e+20, ftol = 1e-4, wolfe = 0.9) {
    .Call('_NGFMfitDistr_LBFGSBtrbFitList', PACKAGE = 'NGFMfitDistr', abc, lm1, empDistrList, abcLB, abcUB, scaleEps, scaleMaxit, distanceFun, max_iterations, maxCore, RIBlib, sequentialUpdate, hgrad, centralDiff, m, epsilon, epsilon_rel, past, delta, max_submin, max_linesearch, min_step, max_step, ftol, wolfe)
}

#' 
#' Ignorance Score
#' 
#' Compute ignorance score given a PMF and a vector of realizations.
#' 
#' @param X  A PMF as a list or dataframe of two numeric vectors. 
#' The first is the support. The second is the probabilities.
#' 
#' @param x  A vector of realizations.
#' 
#' @param redistributePwithin  A boolean. When a realization falls within the
#' range of the PMF's support, \code{redistributePwithin = FALSE} will select
#' the nearest probability mass for calculation, \code{TRUE} will interpolate
#' the two nearest probability masses for calculation. Default to \code{TRUE}.  
#' 
#' @return A numeric vector of the ignorance scores.
#' 
#' @details For a single realization \eqn{x}, the ignorance score = 
#' \eqn{-\log_2 f(x)} where \eqn{f} is the PDF. More details can be found
#' \href{https://journals.ametsoc.org/view/journals/mwre/130/6/1520-0493_2002_130_1653_epfuit_2.0.co_2.xml?tab_body=fulltext-display}{here}.
#' 
#' 
igscore <- function(X, x, redistributePwithin = TRUE) {
    .Call('_NGFMfitDistr_igscore', PACKAGE = 'NGFMfitDistr', X, x, redistributePwithin)
}

igscoreMean <- function(X, truePMF, redistributePwithin = TRUE, symmetricScore = FALSE) {
    .Call('_NGFMfitDistr_igscoreMean', PACKAGE = 'NGFMfitDistr', X, truePMF, redistributePwithin, symmetricScore)
}

findEmpDistrGivenMDR <- function(X, MDR, MDRwanted, sizeWanted, maxCore = 1000L, regridMethod = "r4") {
    .Call('_NGFMfitDistr_findEmpDistrGivenMDR', PACKAGE = 'NGFMfitDistr', X, MDR, MDRwanted, sizeWanted, maxCore, regridMethod)
}

longestIncreasingSubseqSlow <- function(x) {
    .Call('_NGFMfitDistr_longestIncreasingSubseqSlow', PACKAGE = 'NGFMfitDistr', x)
}

longestIncreasingSubseq <- function(x) {
    .Call('_NGFMfitDistr_longestIncreasingSubseq', PACKAGE = 'NGFMfitDistr', x)
}

#'  
#' Longest Nondecreasing Subsequence.
#' 
#' Compute the longest nondecreasing subsequence from a given sequence of numbers.
#' 
#' @param x  A numeric vector.
#' 
#' @return An integer vector of the 1-based indices of the elements in the 
#' subsequence of interest.
#' 
#' @details More details can be found \href{https://en.wikipedia.org/wiki/Longest_increasing_subsequence}{here}.
#' 
#' @example inst/examples/longestNonDecreasingSubseq.R
#'
longestNonDecreasingSubseq <- function(x) {
    .Call('_NGFMfitDistr_longestNonDecreasingSubseq', PACKAGE = 'NGFMfitDistr', x)
}

makeEmpDistr <- function(x, pmf, w, rstSize, regridMethod = "r4", fixedMin = 1e300, fixedMax = 1e300, biasCorrectionMultiplier = 1.0) {
    .Call('_NGFMfitDistr_makeEmpDistr', PACKAGE = 'NGFMfitDistr', x, pmf, w, rstSize, regridMethod, fixedMin, fixedMax, biasCorrectionMultiplier)
}

makeEmpDistrList <- function(X, windows, rstSizes, regridMethod = "r4", maxCore = 1000L, fixedMin = 1e300, fixedMax = 1e300, biasCorrectionMultiplier = 1.0) {
    .Call('_NGFMfitDistr_makeEmpDistrList', PACKAGE = 'NGFMfitDistr', X, windows, rstSizes, regridMethod, maxCore, fixedMin, fixedMax, biasCorrectionMultiplier)
}

mixDistrList <- function(X, Y, rstSizes, Yweights, regridMethod = "r4", maxCore = 1000L) {
    .Call('_NGFMfitDistr_mixDistrList', PACKAGE = 'NGFMfitDistr', X, Y, rstSizes, Yweights, regridMethod, maxCore)
}

mixDistr <- function(X, Y, rstSize, yweight, regridMethod = "r4") {
    .Call('_NGFMfitDistr_mixDistr', PACKAGE = 'NGFMfitDistr', X, Y, rstSize, yweight, regridMethod)
}

movingAverage <- function(x, windowSize, speed, returnWindows = TRUE) {
    .Call('_NGFMfitDistr_movingAverage', PACKAGE = 'NGFMfitDistr', x, windowSize, speed, returnWindows)
}

movingAverageSmoothing <- function(x, windowSize, iterations) {
    .Call('_NGFMfitDistr_movingAverageSmoothing', PACKAGE = 'NGFMfitDistr', x, windowSize, iterations)
}

windowVariances <- function(x, windowSizePercentageIncrement = 0.01, maxCore = 1000L) {
    .Call('_NGFMfitDistr_windowVariances', PACKAGE = 'NGFMfitDistr', x, windowSizePercentageIncrement, maxCore)
}

#' Solve the scale parameter d.
#' 
#' Solve TrB parameter d given a, b, c and the constrained limited mean at 1.
#' 
#' @param abc_lm1  A numeric matrix with four rows. Each column is a vector of
#' \code{(a, b, c)} and the target limited mean at 1.
#' 
#' @param eps  If the difference between TrB's limited mean and \code{lm1} is
#' less than \code{eps}, stop the Newton's iteration. Default to \code{1e-8}.
#' 
#' @param maxit  The maximum number of iterations for Newton's method.
#' Default to \code{100}.
#' 
#' @param useNewton  A boolean. \code{TRUE} invokes Newton's method. 
#' \code{FALSE} invokes bisection. Default to \code{TRUE}.
#' 
#' @inheritParams LBFGSBtrbFitList
#' 
#' @return A numeric vector of \code{d}s. The vector is of of size \code{ncol(abc_lm1)}. 
#' 
solve_d <- function(abc_lm1, eps = 1e-8, maxit = 100L, useNewton = TRUE, RIBlib = "R::pbeta") {
    .Call('_NGFMfitDistr_solve_d', PACKAGE = 'NGFMfitDistr', abc_lm1, eps, maxit, useNewton, RIBlib)
}

upScaleAndBoundPMF <- function(pmf, upperBound, upscaler, regridMethod = "lmm") {
    .Call('_NGFMfitDistr_upScaleAndBoundPMF', PACKAGE = 'NGFMfitDistr', pmf, upperBound, upscaler, regridMethod)
}

